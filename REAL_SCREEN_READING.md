# Real Screen Reading Implementation

## ğŸ¯ What Changed

### Before (Simulation Mode)
- Generated fake coding questions randomly
- No actual screen text extraction
- Topics rotated artificially

### Now (Real Vision-Based Reading)
- **Uses Groq Vision API** (llama-3.2-90b-vision-preview) to analyze screenshots
- **Extracts actual text** from your screen
- **Detects real coding problems** from LeetCode, HackerRank, code editors, etc.
- **Tracks your typing** using KeystrokeMonitor
- **Provides contextual hints** based on what you're actually doing

## ğŸ§  How It Works

### 1. Screen Capture (Every 5 seconds)
```
ğŸ“· Takes screenshot of primary display
```

### 2. Vision Analysis
```
ğŸ” Sends screenshot to Groq Vision API
ğŸ“ AI analyzes: "Is there coding content?"
   - Detects: Coding problems, questions, code editors
   - Extracts: Topic, question text, visible code
   - Returns: Confidence score
```

### 3. Contextual Hint Generation
```
ğŸ¯ If coding detected (confidence > 50%):
   âœ… Sends real question to RAG service
   ğŸ¤– Generates progressive hints with personality
   ğŸ“Š Displays in sidebar
```

### 4. Keystroke Tracking
```
âŒ¨ï¸ Monitors your typing patterns
ğŸ¤” Detects:
   - Hesitation (lots of backspaces)
   - Syntax errors (unmatched brackets)
   - Coding patterns (loops, functions)
   - Long pauses (stuck on problem)

ğŸ’¡ Provides timely hints when you're struggling
```

## ğŸ”§ Technical Stack

### Screen Reading
- **Electron desktopCapturer**: Screenshots
- **Groq Vision API**: llama-3.2-90b-vision-preview
- **Model**: Analyzes images to detect coding content

### Keystroke Monitoring
- **KeystrokeMonitor.js**: Pattern detection
- **Tracks**: Typing speed, backspaces, pauses, patterns

### Hint Generation
- **RAG Service**: Flask backend with Groq LLM
- **Model**: llama-3.3-70b-versatile
- **Features**: Progressive hints, personality-aware

## ğŸ“‹ Testing Instructions

### Step 1: Open a Real Coding Problem
```
1. Open LeetCode, HackerRank, or any coding site in your browser
2. Navigate to a problem (e.g., "Two Sum", "Reverse String")
3. Make sure the problem statement is visible on screen
```

### Step 2: Start the App
```bash
# Terminal 1: Start RAG service
cd /Users/tintuk/calhacks/CalHacks/rag-service
source venv/bin/activate
python app.py

# Terminal 2: Start Desktop App
cd /Users/tintuk/calhacks/CalHacks/socraticcode-desktop
npm start
```

### Step 3: Activate Screen Reading
```
1. Select a personality in the app
2. Click "Start Monitoring"
3. Wait 5-10 seconds for first screen capture
```

### Step 4: Watch the Terminal
You should see:
```
ğŸ“· Capturing screen...
âœ… Screenshot captured, analyzing...
ğŸ¯ Coding content detected! Topic: arrays
ğŸ“ Question: Two Sum - Find two numbers...
```

### Step 5: Start Typing in Your Editor
```
1. Open VS Code or any code editor
2. Start typing code for the problem
3. Make some mistakes (backspace a lot)
4. Watch for contextual hints in the sidebar!
```

## ğŸ” What the Vision API Detects

The AI looks for:

### Coding Platforms
- âœ… LeetCode problems
- âœ… HackerRank challenges
- âœ… CodeWars kata
- âœ… Codeforces problems

### Code Editors
- âœ… VS Code
- âœ… Cursor
- âœ… PyCharm / IntelliJ
- âœ… Sublime Text
- âœ… Any editor with code visible

### Programming Content
- âœ… Problem statements
- âœ… Function signatures
- âœ… Code snippets
- âœ… Error messages
- âœ… Documentation

## ğŸ¨ Contextual Hint Triggers

### Trigger 1: Coding Content Detected
```
Screen shows coding problem
â†’ Generates 3 progressive hints
â†’ Displays in sidebar
```

### Trigger 2: Hesitation Detected
```
User types, deletes, types again (3+ backspaces)
â†’ "User seems stuck"
â†’ Shows subtle hint
```

### Trigger 3: Syntax Error Pattern
```
Unmatched brackets detected in typing
â†’ "Check your syntax"
â†’ Quick tip in sidebar
```

### Trigger 4: Long Pause
```
No typing for 2+ seconds
â†’ Algorithm implementation detected
â†’ Gentle nudge with hint
```

## ğŸš€ API Information

### Groq Vision API
- **Model**: llama-3.2-90b-vision-preview
- **Purpose**: Extract text/code from screenshots
- **API Key**: Already configured in code
- **Rate Limit**: Check Groq dashboard

### Groq LLM API
- **Model**: llama-3.3-70b-versatile
- **Purpose**: Generate Socratic hints
- **Temperature**: 0.7 (creative hints)

## ğŸ§ª Testing Scenarios

### Scenario 1: LeetCode Test
1. Open: https://leetcode.com/problems/two-sum/
2. Ensure problem description visible
3. Start monitoring
4. **Expected**: Detects "Two Sum" problem, provides hints about hash maps

### Scenario 2: Local Code Editor
1. Open VS Code
2. Create file: `solution.py`
3. Start typing a function
4. Make mistakes (backspace frequently)
5. **Expected**: Detects coding, shows syntax hints when stuck

### Scenario 3: Multi-Window
1. LeetCode on left, VS Code on right
2. Screenshot captures both
3. **Expected**: Prioritizes detecting the coding problem

## âš¡ Performance Notes

### Screenshot Capture
- **Frequency**: Every 5 seconds
- **Resolution**: 1280x720 (optimized)
- **Format**: PNG â†’ Base64

### Vision API Call
- **Latency**: 1-3 seconds
- **Tokens**: ~300-500 per analysis
- **Cost**: Minimal (Groq is fast/cheap)

### Keystroke Detection
- **Real-time**: Immediate pattern detection
- **Buffer**: Last 50 keystrokes kept
- **Patterns**: Analyzed on-the-fly

## ğŸ¯ Next Steps for Better Accuracy

### Option 1: Enhance Prompt Engineering
Make the vision analysis prompt more specific to your use case

### Option 2: Add OCR Fallback
Use Tesseract.js for offline OCR when API is unavailable

### Option 3: Multi-Monitor Support
Detect which monitor has coding content

### Option 4: Active Window Detection
Focus only on the active window for faster analysis

## ğŸ› Troubleshooting

### No Content Detected?
```
âœ“ Is the coding problem clearly visible?
âœ“ Is the text large enough to read?
âœ“ Is the window not minimized?
âœ“ Check terminal for Vision API errors
```

### Vision API Errors?
```
âœ“ Check Groq API key is valid
âœ“ Check internet connection
âœ“ Check rate limits on Groq dashboard
âœ“ Look for error messages in terminal
```

### Hints Not Appearing?
```
âœ“ Is RAG service running? (port 5001)
âœ“ Is monitoring active? (green indicator)
âœ“ Is sidebar expanded? (click indicator dot)
âœ“ Check terminal for hint generation logs
```

## ğŸ“Š Success Metrics

You'll know it's working when you see:
```
âœ… "Coding content detected" in terminal
âœ… Real question extracted from your screen
âœ… Hints appear in sidebar within 10 seconds
âœ… Hints are relevant to the actual problem
âœ… Typing patterns trigger contextual help
```

## ğŸ‰ That's It!

The system now:
- âœ… **Reads your actual screen** (not simulated)
- âœ… **Extracts real coding problems** (via Vision API)
- âœ… **Tracks your typing** (via KeystrokeMonitor)
- âœ… **Provides contextual hints** (based on real behavior)
- âœ… **No fake scenarios** (all real detection)

Ready to test? Follow the instructions above! ğŸš€

